{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute if necessary\n",
    "# %%capture\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 7: Modelos Integrados (ARIMA y SARIMA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Instrucciones__: A continuación hay una lista de funciones que debe implementar o tareas que debe desarrollar. La descripción de cada una de ellas se encuentra en la definición de cada una de las funciones.\n",
    "\n",
    "La entrega de la práctica será en la siguiente sesión a menos que la indicación sea otra. La revisión iniciará al iniciar la sesión y únicamente podrá ser evaluada durante la duración de la sesión."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Para esta práctica se deben usar bibliotecas__. Se recomienda el uso de:\n",
    "\n",
    "- scikit-learn (https://scikit-learn.org/stable/)\n",
    "- plotly express (https://plotly.com/python/plotly-express/)\n",
    "- statsmodels (https://www.statsmodels.org/stable/index.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación 1\n",
    "\n",
    "Seleccione algun dataset de su preferencia que sea relacionado a series de tiempo. Particione sus datos para poder evaluar el desempeño de su práctica (__conjunto de test__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbformat>=4.2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar csv kalimati_tarkari_dataset.csv y visualizarlo\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('kalimati_tarkari_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionar en la columna Commodity las entradas con el valor 'Potato White' y visualizarlo\n",
    "df = df[df['Commodity'] == 'Onion Dry (Indian)']\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med = df[['Date', 'Average']]\n",
    "train = df_med.loc['2013-06-16':'2021-03-01']\n",
    "test = df_med.loc['2021-03-01':'2021-05-13']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación 2\n",
    "\n",
    "Realice un análisis exploratorio de datos y el preprocesamiento necesario para el dataset seleccionado. El análisis realizado debe respaldar (preferentemente mediante el uso de gráficas) las decisiones que tome para la siguiente asignación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionar las columnas Date, Average y visualizarlo\n",
    "df_med = df[['Date', 'Average']]\n",
    "df_low = df[['Date', 'Minimum']]\n",
    "df_high = df[['Date', 'Maximum']]\n",
    "\n",
    "df_pred = df_med.copy()\n",
    "\n",
    "df_med.head()\n",
    "\n",
    "#graficar con plotly-express los 3 dataframes df_med, df_low y df_high \n",
    "fig = px.line(df_med, x='Date', y='Average', title='Average')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividir el dataframe df_med en 2 dataframes: df_train y df_test en 80% y 20% respectivamente\n",
    "\n",
    "X = df_med.iloc[:, :-1].values\n",
    "y = df_med.iloc[:, 1].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación 3\n",
    "\n",
    "Ajuste un modelo ARMA, ARIMA o SARIMA segun sea conveniente para sus datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder evaluar que modelo nos conviene más optamos por seguir los siguientes pasos: \n",
    "\n",
    "Aquí hay algunos pasos que puedes seguir para evaluar qué modelo es más apropiado:\n",
    "\n",
    "- __Visualización de datos:__ Comienza por trazar la serie temporal de los datos que tienes, es decir, los valores promedio en función de la fecha. Esto te permitirá observar cualquier patrón evidente, tendencia o estacionalidad.\n",
    "\n",
    "- __Estacionariedad:__ Evalúa si la serie temporal es estacionaria. Una serie estacionaria es aquella cuyas propiedades estadísticas (como media y varianza) son constantes en el tiempo. Puedes utilizar métodos como la prueba de Dickey-Fuller aumentada (ADF) para verificar la estacionariedad.\n",
    "\n",
    "\n",
    "- __Autocorrelación:__ Examina la autocorrelación de la serie temporal. La autocorrelación es la relación entre los valores pasados y futuros en una serie temporal. Puedes utilizar la función de autocorrelación (ACF) y la función de autocorrelación parcial (PACF) para evaluar la correlación en diferentes rezagos.\n",
    "Componentes estacionales: Si observas patrones estacionales en los datos, como fluctuaciones regulares que se repiten, puedes considerar modelos como SARIMA que incorporan componentes estacionales."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- Visualizacion de datos\n",
    "\n",
    "Visualizando la anterior grafica podemos observar que existe un patrón de fechas en finales de año"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Estacionariedad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se realiza la prueba de Dickey-Fuller Aumentada (ADF), el objetivo es determinar si una serie temporal tiene una raíz unitaria, lo que indica la presencia de tendencia o no estacionariedad en los datos. La hipótesis nula en esta prueba es que la serie temporal tiene una raíz unitaria, es decir, no es estacionaria.\n",
    "\n",
    "Al realizar la prueba ADF, se obtiene un estadístico ADF específico que se compara con los valores críticos correspondientes a diferentes niveles de significancia, como el 1%, 5% y 10%. Estos valores críticos representan los umbrales a los que se compara el estadístico ADF para determinar si se rechaza o no la hipótesis nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Extrae la columna de interés (Average en este caso)\n",
    "average_data = df_med['Average']\n",
    "\n",
    "# Aplica la prueba Dickey-Fuller aumentada\n",
    "result = adfuller(average_data)\n",
    "\n",
    "# Extrae los valores de la prueba y los p-valores\n",
    "adf_statistic = result[0]\n",
    "p_value = result[1]\n",
    "critical_values = result[4]\n",
    "\n",
    "# Imprime los resultados\n",
    "print(f'Estadístico ADF: {adf_statistic}')\n",
    "print(f'p-valor: {p_value}')\n",
    "print('Valores críticos:')\n",
    "for key, value in critical_values.items():\n",
    "    print(f'   {key}: {value}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor del estadístico ADF (-3.430956211048367) es menor que el valor crítico del 1% (-3.432750244284443). Esto significa que se rechaza la hipótesis nula al 1% de nivel de significancia. En otras palabras, hay evidencia suficiente para concluir que los datos no tienen una raíz unitaria y son estacionarios al 1% de nivel de significancia. Esta es una conclusión bastante sólida.\n",
    "\n",
    "Sin embargo, el valor del estadístico ADF es mayor que los valores críticos del 5% (-2.8626004539809906) y del 10% (-2.567334514143628). Esto implica que no se puede rechazar la hipótesis nula al 5% y 10% de nivel de significancia. En otras palabras, no hay suficiente evidencia para afirmar que los datos son estacionarios al 5% y 10% de nivel de significancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med['Diferencia entre precios'] = df_med['Average'] - df_med['Average'].shift(1)\n",
    "df_med.dropna(subset = [\"Diferencia entre precios\"], inplace=True)\n",
    "df_med.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_fuller_result = adfuller(df_med['Diferencia entre precios'])\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12, 5]); # Set dimensions for figure\n",
    "df_med['Diferencia entre precios'].plot()\n",
    "plt.title('Precio promedio de la cebolla en el mercado de Kalimati - Diferencia entre precios')\n",
    "plt.ylabel('Precio')\n",
    "plt.grid(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.-Autocorrelacion\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función tsaplots en statsmodels.graphics de Python proporciona varias tramas (plots) para el análisis y visualización de series de tiempo. Esta función se utiliza en combinación con otros módulos y funciones de statsmodels para crear gráficos relacionados con el análisis de series temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realiza una grafica de autocorrelacion con plotly-express de la columna Average del dataframe df_med y la de autocorrelacion parcial\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "plot_acf(df_med['Average'], lags=1000)\n",
    "plot_pacf(df_med['Average'], lags=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modelos ARIMA y SARIMA: Si la serie es estacionaria y no muestra patrones estacionales evidentes, puedes considerar modelos ARIMA. Un modelo ARIMA es adecuado cuando hay una dependencia de los valores pasados y diferencias en los datos para hacerlos estacionarios. Si hay componentes estacionales, puedes considerar modelos SARIMA que extienden ARIMA para manejar la estacionalidad.\n",
    "\n",
    "- Modelo ARMA: Si no hay necesidad de diferenciar los datos para hacerlos estacionarios y no hay patrones estacionales, un modelo ARMA puede ser apropiado. El modelo ARMA combina los componentes autorregresivos (AR) y de media móvil (MA) para modelar la dependencia y la estructura de ruido en la serie temporal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que determinamos que utilizaremos un modelo __SARIMA__ para poder realizar nuestro forecasting.\n",
    "\n",
    "Nuestro modelo entrenado luce de esta manera."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "añadir aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kalimati_tarkari_dataset.csv')\n",
    "df.head()\n",
    "#Seleccionar en la columna Commodity las entradas con el valor 'Potato White' y visualizarlo\n",
    "df = df[df['Commodity'] == 'Onion Dry (Indian)']\n",
    "df_med = df[['Date', 'Average']]\n",
    "\n",
    "#hacer index la columna Date y convertirlo en formato fecha\n",
    "df_med['Date'] = pd.to_datetime(df_med['Date'])\n",
    "df_med.set_index('Date', inplace=True)\n",
    "df_med.head()\n",
    "df_med2 = df_med.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cufflinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Plotly & Cufflinks libraries and run it in Offline mode\n",
    "import plotly.offline as py\n",
    "import cufflinks as cf\n",
    "py.init_notebook_mode(connected=True)\n",
    "py.enable_mpl_offline()\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med.iplot(title=\"Valor de la cebolla en el mercado de Kalimati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "#dejar que Date sea DateTimeIndex\n",
    "\n",
    "df_med.index = pd.to_datetime(df_med.index)\n",
    "df_med = df_med.asfreq('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_med.index.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med = df_med.fillna(df_med.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = seasonal_decompose(df_med, model='multiplicative')\n",
    "fig = result.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función se utiliza para encontrar automáticamente los parámetros óptimos de un modelo ARIMA (Autoregressive Integrated Moving Average) para una serie de tiempo.\n",
    "\n",
    "El modelo ARIMA es un enfoque estadístico utilizado para modelar y predecir datos de series de tiempo. Consiste en tres componentes principales: el componente autoregresivo (AR), el componente de media móvil (MA) y el componente de integración (I).\n",
    "\n",
    "En el código que has proporcionado, se crea un modelo ARIMA utilizando la función auto_arima(). A continuación se explican los parámetros utilizados en la función:\n",
    "\n",
    "- df_med: Es la serie de tiempo a la que se le desea ajustar el modelo ARIMA.\n",
    "- start_p y start_q: Son los valores iniciales para los parámetros autoregresivos (p) y de media móvil (q), respectivamente.\n",
    "- max_p y max_q: Son los valores máximos permitidos para los parámetros p y q. Estos parámetros limitan la búsqueda de los mejores valores en un rango específico.\n",
    "- m: Es la frecuencia de la serie de tiempo, que en este caso se establece en 7 para indicar una serie semanal.\n",
    "- start_P: Es el valor inicial para el parámetro de autoregresión estacional (P).\n",
    "- seasonal: Indica si se debe utilizar un modelo estacional ARIMA.\n",
    "- d y D: Son los órdenes de diferenciación para los componentes no estacionales y estacionales, respectivamente.\n",
    "- trace: Indica si se debe imprimir información de depuración durante la búsqueda de los mejores parámetros.\n",
    "- error_action y suppress_warnings: Son configuraciones para manejar errores y advertencias.\n",
    "- stepwise: Indica si se debe utilizar un enfoque paso a paso para buscar los mejores parámetros.\n",
    "\n",
    "Al ejecutar este código, se obtendrá un modelo ARIMA ajustado a la serie de tiempo df_med con los mejores parámetros encontrados automáticamente según los criterios especificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "stepwise_model = auto_arima(df_med, start_p=1, start_q=1,\n",
    "                           max_p=3, max_q=3, m=7,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stepwise_model.aic())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos nuestro valores de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_med2.loc['2013-06-16':'2021-03-01']\n",
    "test = df_med2.loc['2021-03-01':'2021-05-13']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_model.fit(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación 4\n",
    "\n",
    "Realice un diagnostico de su modelo para verificar que es correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_forecast = stepwise_model.predict(n_periods=73)\n",
    "print(future_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_forecast = pd.DataFrame(future_forecast, index=test.index, columns=['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([test, future_forecast], axis=1).iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Obtener las predicciones del modelo\n",
    "predictions = stepwise_model.predict(n_periods=len(test))\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "mse = mean_squared_error(test, predictions)\n",
    "mae = mean_absolute_error(test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprimir las metricas de evaluacion \n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación 5\n",
    "\n",
    "Obtenga el forecast para los datos de test, grafique los valores reales y las predicciones en conjunto. Obtenga el error de regresión para los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_model.fit(df_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_forecast_1week = stepwise_model.predict(n_periods=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(future_forecast_1week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U kaleido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear figura y ejes\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Graficar la serie de tiempo original\n",
    "ax.plot(df_med.index, df_med['Average'], label='Serie de tiempo original')\n",
    "\n",
    "# Graficar las predicciones\n",
    "ax.plot( future_forecast_1week, label='Predicciones')\n",
    "\n",
    "# Configurar límites del eje x\n",
    "start_date = pd.to_datetime('2021-02-01')\n",
    "end_date = pd.to_datetime('2021-07-01')\n",
    "ax.set_xlim(start_date, end_date)\n",
    "\n",
    "# Configurar etiquetas y título\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('Predicciones para la próxima semana')\n",
    "\n",
    "# Rotar las etiquetas del eje x para mejorar la legibilidad\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Mostrar la leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "fecha_inicio = datetime.strptime(\"2021-05-13\", \"%Y-%m-%d\")\n",
    "diferencia = timedelta(days=182)\n",
    "fecha_resultante = fecha_inicio - diferencia\n",
    "\n",
    "print(fecha_resultante.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "fecha_inicio = date(2021, 3, 1)\n",
    "fecha_fin = date(2021, 5, 13)\n",
    "diferencia = fecha_fin - fecha_inicio\n",
    "\n",
    "print(diferencia.days)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
